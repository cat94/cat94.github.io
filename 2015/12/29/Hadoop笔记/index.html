<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Ben Wong,wenbinben@gmail.com"><title>HDFS起步笔记 · 沈小黑的菜园</title><meta name="description" content="阅读Hadoop官方文档，并记录之。
安装自不提，在单机上使用Single Node Setup模式即可，具体安装步骤无非按部就班，在官网上即可查询。

Hadoop Cluster的三个模式：这一小节和下一小节严格来说不算是HDFS的内容，只是按照顺序看下来，一并进行记录。

Local (Sta"><meta name="keywords" content="Hexo,HTML,Ben,CSS,安卓,android,Linux,linuxdeepin"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">沈小黑的菜园</a></h3><div class="description"><p>Nothing lasts forever.</p></div></div></div><ul class="social-links"><li><a href="https://twitter.com/Ben_wenbin"><i class="fa fa-twitter"></i></a></li><li><a href="http://instagram.com/hwbinbenben"><i class="fa fa-instagram"></i></a></li><li><a href="/atom.xml"><i class="fa fa-rss"></i></a></li><li><a href="http://weibo.com/ben0036"><i class="fa fa-weibo"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai</a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="https://secure.gravatar.com/avatar/e71df8021446fe9759a9928b1dd5c28d?s=180&amp;r=G&amp;d="></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>HDFS起步笔记</a></h3></div><div class="post-content"><p>阅读Hadoop官方文档，并记录之。</p>
<p>安装自不提，在单机上使用Single Node Setup模式即可，具体安装步骤无非按部就班，在<a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="external">官网</a>上即可查询。</p>
<a id="more"></a>
<h2 id="Hadoop-Cluster的三个模式："><a href="#Hadoop-Cluster的三个模式：" class="headerlink" title="Hadoop Cluster的三个模式："></a>Hadoop Cluster的三个模式：</h2><p>这一小节和下一小节严格来说不算是HDFS的内容，只是按照顺序看下来，一并进行记录。</p>
<ul>
<li>Local (Standalone) Mode <b>(默认)</b></li>
<li>Pseudo-Distributed Mode</li>
<li>Fully-Distributed Mode</li>
</ul>
<p>Standalone模式运行为一个Java单线程</p>
<p>在Pseudo-Distributed模式中，只有一个节点，但是所有的Hadoop后台程序都运行在分别不同的进程中。</p>
<p>Fully-Distributed模式<br>Hadoop配置文件分成两种：</p>
<ul>
<li>只读的默认配置文件：core-default.xml, hdfs-default.xml, yarn-default.xml and mapred-default.xml</li>
<li>自定义配置文件：etc/hadoop/core-site.xml, etc/hadoop/hdfs-site.xml, etc/hadoop/yarn-site.xml and etc/hadoop/mapred-site.xml</li>
</ul>
<p>HDFS的后台驻留程序是NameNode, SecondaryNameNode和DataNode。YARN的则是 ResourceManager, NodeManager和WebAppProxy。如果使用了MapReduce，那么还会运行MapReduce Job History Server。</p>
<p>管理员应该使用etc/hadoop/hadoop-env.sh、etc/hadoop/mapred-env.sh或者etc/hadoop/yarn-env.sh这些脚本设置各种OPTS(比如HADOOP_NAMENODE_OPTS)来指定后台驻留程序的环境。</p>
<h2 id="FileSystem-Shell"><a href="#FileSystem-Shell" class="headerlink" title="FileSystem Shell"></a>FileSystem Shell</h2><p>FileSystem Shell囊括了多种shell形式的命令来直接和HDFS、本地文件系统、HFTP等Hadoop支持的文件系统进行交互。命令形式为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">haddop fs &lt;args&gt;</div></pre></td></tr></table></figure>
<p>在FileSystem Shell中，文件以scheme://autority/path的形式表示(HDFS的scheme为’hdfs’,本地文件的scheme为’local’)。如果不指定scheme和authority，那么会使用配置中的默认选项。一个HDFS路径可以表示为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs://namenodehost/parent/child</div></pre></td></tr></table></figure>
<p>如果配置文件中已经指明hdfs://namenodehost，那么可以直接表示为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/parent/child</div></pre></td></tr></table></figure>
<h3 id="args操作"><a href="#args操作" class="headerlink" title="args操作"></a>args操作</h3><p>在hadoop fs 命令后的args,包括这种常用的shell命令。在命令前加上’-‘之后，所有的格式都和原来一样，比如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -ls /users/</div></pre></td></tr></table></figure>
<p><a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html" target="_blank" rel="external">官方教程</a>列举了所有的args命令。</p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>HDFS主要由管理文件元信息的NameNode和存储数据的DataNode组成。Clients从NameNode处请求文件信息/修改请求，然后和DataNode进行直接的IO操作。</p>
<p>这里列举一些官网提及的HDFS功能，关于他们的命令行操作不作记录，在Hadoop的<a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html" target="_blank" rel="external">命令行文档</a>中有详细的描述。这些命令行操作和 Hadoop FileSystem 是两套体系，很多命令都只有在HDFS中才有，以 ‘hdfs command’这样的方式进行调用。</p>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><p>NameNode会记录所有的数据修改历史到edits文件中。当NameNode启动的时候，它会从一个叫做fsimage的image file中读取快照，并且将edits中的修改日志重新操作一遍。这样fsimage就更新了一次。这样可能会导致问题：1.NameNode因为要在启动时进行大量的合并操作，所以启动很慢。2.如果NameNode长时间运行，edits文件可能会太大而导致下一次合并更加慢。</p>
<p>Secondary NameNode会在间隔一段时间或edits超过一定大小时，将fsimage和edits操作进行合并生成新的fsimage。</p>
<ul>
<li>dfs.namenode.checkpoint.period,最大间隔时间</li>
<li>dfs.namenode.checkpoint.txns,edits最大尺寸</li>
</ul>
<h3 id="Checkpoint-Node"><a href="#Checkpoint-Node" class="headerlink" title="Checkpoint Node"></a>Checkpoint Node</h3><p>Checkpoint Node也会将fsimage和edits进行合并，和Secondary NameNode不同的是，它会从NameNode下载fsimage和edits，在本地合并之后将其上传回NameNode上。</p>
<h3 id="Backup-Node"><a href="#Backup-Node" class="headerlink" title="Backup Node"></a>Backup Node</h3><p>Backup Node比Checkpoint Node更进一步：它不需要定期从NameNode下载fsimage，而是在内存中存留有和NameNode一致的fsimage，Backup Node从NameNode处接收日志流并且和内存中的fsimage进行合并，创建一份数据备份。这样的话当NameNode失效之后，Backup Node可以真正意义上地进行热切换。目前最新版本的Hadoop已经弃用了Checkpoint Node,转而使用Backup Node。</p>
<p>目前(2.7.2)只支持一个Backup Node,官网上的说法是将会在未来实现多个Backup Node。</p>
<h3 id="Balancer"><a href="#Balancer" class="headerlink" title="Balancer"></a>Balancer</h3><p>Hadoop可能因为新增节点、数据存放策略(比如把数据放在本机减少网络IO)等原因，导致数据分布不均匀。使用Balancer工具可以分析块存放并且跨DataNode重新平衡块位置。</p>
<h3 id="Safemode"><a href="#Safemode" class="headerlink" title="Safemode"></a>Safemode</h3><p>在NameNode启动的过程中，它会加载fsimage和edits日志，然后等待DataNodes报告自己的块信息。在这个等待的过程中，NameNode就处于Safemode。在Safemode的阶段，NameNode对于HDFS是只读的，在DataNode报告绝大多数(这个”绝大多数”的参数通过dfs.safemode.threshold.pct进行设置)块是正常的时候，NameNode就会自动退出Safemode。也可以通过’hdfs dfsadmin -safemode’来手动进入Safemode。</p>
<h3 id="fsck"><a href="#fsck" class="headerlink" title="fsck"></a>fsck</h3><p>fsck命令用于检查HDFS的多文件问题。比如丢失块或者在relicated数量之下。通常NameNode会自动修复大多数的错误，而fsck并不负责对文件进行修复。默认情况下fsck忽略已经打开的文件，但是也可以通过设置option来报告所有文件的状态。</p>
<h3 id="Recovery-Mode"><a href="#Recovery-Mode" class="headerlink" title="Recovery Mode"></a>Recovery Mode</h3><p>为了应对所有的metadata存储结点都崩溃的情况，HDFS提供了一种特殊的启动模式：Recovery mode。这种模式允许在metadata结点崩溃的时候恢复绝大多数数据。在Recovery mode中，NameNode会在命令行交互式地提示你可以做的操作来恢复数据。如果想要自动完成，可以通过 -force 选项来进行，这样的话，NameNode会自动选择最合理的操作。</p>
<h3 id="DataNode-Hot-Swap-Drive"><a href="#DataNode-Hot-Swap-Drive" class="headerlink" title="DataNode Hot Swap Drive"></a>DataNode Hot Swap Drive</h3><p>DataNode支持热切换驱动，用户可以在DataNode运行时增加或者切换data卷。具体的过程如下：</p>
<ul>
<li>如果有新的存储目录，用户应该格式化并挂载目录</li>
<li>更新dfs.datanode.data.dir来重新指定data卷路径</li>
<li>运行hdfs dfsadmin -reconfig datanode HOST:PORT start开始配置过程，可以运行hdfs dfsadmin -reconfig datanode HOST:PORT status来查看配置状态</li>
<li>现在可以安全地将被替换掉的卷卸载掉了。</li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2015-12-29</span><i class="fa fa-tag"></i><a href="/tags/大数据/" title="大数据" class="tag">大数据 </a><a href="/tags/Hadoop/" title="Hadoop" class="tag">Hadoop </a></div></div></div></div><div class="share"><div class="evernote"> <a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"> <a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"> <a href="http://twitter.com/home?status=,http://www.shenjianan.net/2015/12/29/Hadoop笔记/,沈小黑的菜园,HDFS起步笔记,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2016/01/07/《HBase实战》随笔——数据操作/" title="《HBase实战》随笔——数据操作" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2015/11/29/Java并发编程实战-读书笔记/" title="Java并发编程实战 读书笔记" class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>